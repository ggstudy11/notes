# Redis
## 实践1： Redis - 共享Session

### 场景：

基于Session实现登录流程，用户在提交手机号后，会校验手机号是否合法，如果不合法，则要求用户重新输入手机号，如果手机号合法，后台此时生成对应的验证码，同时将验证码进行保存，然后通过短信的方式将验证码发送给用户。  
用户将验证码和手机号进行输入，后台从Session中拿到当前验证码，然后和用户输入的验证码进行校验，如果用户不存在，则为用户创建账号信息，保存到数据库，无论是否存在，都会把用户信息保存到session中，方便后续获得当前登录信息。  
用户在请求时，会从cookie中携带着JessionId到后台，后台通过JsessionId从session中获取用户信息，如果没有session信息，则进行拦截，如果有session信息，则将用户信息保存到threadLocal中，并且放行。 

### 核心问题：  
分布式session，session原理，cookie原理。

仅考虑上述场景我们给出以下的解决方案：  
1. 用户输入手机号，点击发送验证码，后端进行手机号校验，如果合法则产生验证码，并且存入session中，这里前端会得到一个sessionId  
2. 用户填入验证码，并且携带session进行登录，后端根据session中的验证码和用户表单填入的验证码进行校验，如果一致则成功，若没有用户则创建，并存入到session中，后续作为登录鉴权。黑马这里的解决方案有问题，应该存入手机号，否则前后两次手机号不一致也能够进行登录。  

### 分布式session问题：  
当后端有多台tomcat服务器时，前端发出请求时，会发送到不同的服务器上，session会存入到不同服务器中，当用户把自己信息存入到第一台服务器上的session中，但第二次这个用户访问到了第二台tomcat，那么在第二台服务器上，肯定没有第一台服务器存放的session，如何解决？  
1. 对于特定的ip访问进行hash映射，一个ip就对应一个服务器，但是这样就会存在一个问题，当这台服务宕机时就会出现问题。  
2. session复制，每个tomcat服务器上有不同的session，但是每当任意的服务器session修改时，都会同步给其他的Tomcat服务器的session，就可以实现session共享，同样存在问题，每台服务器中都有完整一份session数据，服务器压力过大，session拷贝数据时，可能会出现延迟。  
所以可以通过redis来完成，我们把session换成redis，redis数据本身就是共享的，就可以避免session共享问题。  

### 基于Redis实现共享session登录  
1. 随机生成token，存储键值对"某种形式token" + “userInfo”, 返回前端token  
2. 前端每次访问携带token, 在redis中查询userInfo  


### 附加：  
解决状态登录刷新问题：加一层拦截器用于刷新

## 实践2： 商户查询缓存

为什么要使用缓存：速度快、好用  
缓存数据存储于代码中，而代码运行在内存中，内存的读写性能远高于磁盘，缓存可以大大降低用户访问并发量带来的服务器读写压力。  
实际开发过程中，企业数据量，少则几十万，多则几千万，这么大数据量，如果没有缓存作为“避震器”, 系统是支持不住的，所以需要用到缓存技术。  
优点：降低后端负载、提高读写效率、降低响应实践  
缺点：数据一致性成本，代码维护成本，运维成本  

缓存模型与思路：  
标准的操作方式就是查询数据库之前先查询缓存，如果缓存数据存在，则直接从缓存中返回，如果缓存数据不存在，再查询数据库，然后将数据存入redis  

缓存更新策略：  
缓存更新策略是redis节约内存而设计出来的一个东西，主要是因为内存数据宝贵，当我们向redis插入太多数据，此时就可能导致缓存中的数据过多，redis会对部分数据进行更新，或者把他叫为淘汰更合适。  
内存淘汰：redis自动进行，当redis内存达到咱们设定的max-memory的时候，会自动出发淘汰机制，淘汰掉一些不重要的数据  
超时剔除: 当我们给redis设置了过期时间ttl之后，redis会将超时的数据进行删除，方便我们继续使用缓存  
主动更新: 我们可以手动调用方法把缓存删掉，通常用于解决缓存和数据库不一致问题

数据库缓存不一致解决方案：  
由于我们的缓存的数据源来自于数据库，而数据库的数据是会发生变化，因此，如果当数据库中数据发生变化，而缓存没有同步时，就会存在一致性问题，其后果是:  
1. Cache Aside Pattern人工编码方案：缓存调用者在更新完数据库后再去更新缓存，也称之为双写方案  
2. Read/Wriet Through Pattern: 由系统本身完成，数据库与缓存问题交由系统本身去处理  
3. Write Behind Caching Pattern: 调用者只操作缓存，其他线程去异步处理数据库，实现最终一致  

方案1  
每次操作数据库后，都需要操作缓存，但是如果没有人查询，那么这个更新动作实际上只有最后一次生效，中间的更新动作意义并不大，我们可以把缓存删除，等待再次查询时，将缓存中的数据加载出来。  
删除缓存：更新数据库时让缓存失效，查询时再更新缓存
如何保证缓存与数据库的操作的同时成功或失败？  
> 单体系统，将缓存与数据库操作放在一个事务  
> 分布式系统，利用分布式事务方案  

在操作时应该先操作数据库还是先操作缓存呢？ 先操作数据库，假如先操作缓存将缓存删除后，另一个线程进行访问导致缓存被更新为旧数据，必须等到下一次数据库操作才能消除。

### 实践3： 缓存穿透

缓存穿透指的是客户端请求的数据在缓存中和数据库中都不存在，这样缓存永远不会生效，这些请求都会打到数据库。  
常见的解决方案：  
1. 缓存空对象  
    优点：实现简单、维护方便  
    缺点：额外内存消耗、短期不一致性  
2. 布隆过滤  
    优点：内存占用比较少，没有多余key  
    缺点：实现复杂、存在误判可能  

缓存空对象思路分析：当客户端访问不存在的数据时，先请求redis，但是此时redis没有数据，此时会访问到数据库，但是数据库中也没有数据，这个数据穿透了缓存，直击数据库，我们都知道数据库能承载的并发远不如redis这么高，如果大量的请求同时过来访问这种不存在的数据，这些请求都会访问到数据库，简单的解决方案就是哪怕这个数据在数据库中不存在，我们也把这个数据写入到redis中去，这样下次用户来访问这个不存在的数据时，redis就能找到这个数据不会进入缓存。  

布隆过滤：通过一个庞大的二进制数组，通过布隆过滤器判断这个数据是否存在。其实是事先写入的。  

缓存穿透的其他解决方案：做好热点参数的限流，加强用户权限校验，做好数据的基础格式校验等

## 实践4： 缓存雪崩

缓存雪崩指的是同一时段大量的缓存key同时失效或Redis服务宕机，导致大量请求到达数据库，带来巨大压力。  

>解决方案：  
>1. 给不同的Key的TTL添加随机值  
>2. 利用Redis集群提高服务的可用性  
>3. 给缓存业务添加降级限流策略  
>4. 给业务添加多级缓存  

## 实践5：缓存击穿

缓存击穿也叫热点key问题，就是一个高并发并且缓存重建事务较复杂的key突然失效了，无数氢气访问会在瞬间给数据库带来巨大冲击。

解决方案：  
- 互斥锁
- 逻辑过期

逻辑分析：假设线程1在查询缓存之后，本来应该去查询数据库，然后把这个数据重新加载到缓存的，此时只要线程1走完这个逻辑，其他线程都能从缓存中加载这些数据了，但是假设在线程1没有走完的时候，后续的线程2，3，4同时过来访问当前这个方法，那么这些线程都不能从缓存中查询到数据，那么他们就会同一时刻来访问查询缓存，都没查到，接着同一时间去访问数据库，这样对数据库访问压力特别大  

互斥锁：  
因为锁能实现互斥，假设线程已经过来，只能一个人访问数据库，这样避免了对数据库访问压力过大，但是也会影响查询的性能，因为多线程现在变成了串行。  
假设线程1访问，当前缓存没有命中，此时获得了锁资源对数据库进行操作，线程2此时过来要等待线程1执行完毕，再去缓存中获取。  

逻辑过期：  
假设我们不设置过期时间，就不会有缓存击穿问题，这里考虑用逻辑过期的方案。
我们把过期时间设置在redis的value中，这个过期时间不会直接作用于redis，而是通过我们后续的逻辑去处理，假设线程1去查询缓存，然后从value中判断出来当前的数据已经过期了，此时线程1去获得互斥锁，其他线程会被阻塞，获取了锁的线程会开启一个线程去执行过期数据缓存的重构，其他被阻塞的线程直接放回过期数据。  

互斥锁实现：  
1. 从redis中查询缓存
2. 判断缓存值是否为空，不为空则反序列化返回
3. 缓存值为空，代表缓存击穿措施
4. 缓存为空，则代表缓存过期，需要缓存重建
5. 获取互斥锁，进行缓存重建，这里的互斥锁为redis.setnx 同时需要过期时间防止宕机导致的死锁问题
6. 其他线程获取锁失败后休眠，再递归查询。
7. 将查询到的写入缓存，或进行防止缓存击穿的措施。

这里存在几个问题，互斥锁的释放时间问题，如果业务还没有执行完但是锁已经被释放了呢？递归查询问题，考虑是否利用循环读取缓存数据呢？

逻辑过期实现：
1. 从redis中查询缓存
2. 判断缓存值是否为空，不为空则反序列化返回
3. 缓存值为空，代表缓存击穿措施
4. 缓存为空，则代表缓存过期，需要缓存重建
5. 获取互斥锁，进行缓存中间，这里互斥锁为redis.setnx 同时需要过期时间
6. 其他线程获取锁失败后直接返回过期数据。

### 实践6：优惠券秒杀

全局唯一ID：  
当用户抢购时会自动生成订单并保存到优惠券订单表中，而订单表如果使用数据库自增ID就会出现一些问题：
> id的规律性太明显  受表单数据量的限制

随着我们商城规模越来越大，mysql的单表的容量不宜超过500w，数据量过大之后，我们要进行拆库拆表，但拆分表了之后，他们从逻辑上讲他们是同一张表，所以他们的id是不能一样的，于是我们要保证id的唯一性

我们可以利用Redis自增的数值进行全局唯一ID的拼接，利用时间戳和序列号(日期进行拼接)  

实现秒杀下单：  
点击抢购时，后端需要做两点判断：  
- 秒杀是否开始或结束，如果秒杀尚未开始或已经结束则无法下单
- 库存是否充足，不足则无法下单  
下单核心逻辑分析：  
当用户开始下单，查询优惠券信息，查询到优惠券信息判断是否满足秒杀条件。  
其中有超卖问题的产生  
假设线程1查询库存，发现库存大于1，准备扣减库存，而线程2也查询库存，发现数量大于1，准备扣减库存，最终多个线程一起去扣减库存，导致超卖。这是常见的多线程安全问题，针对这一问题的常见解决方案就是枷锁，而对于加锁，我们有两种解决方案：
1. 悲观锁：认为线程安全问题一定会发生，因此在操作数据之前先获取锁，确保线程安全
2. 乐观锁：认为线程安全问题不一定会发生，因此不加锁，只是在更新数据时去判断，是否有其他线程对数据做了改变

这里我们采用乐观锁的方式进行问题解决：乐观锁的代表就是cas，利用cas进行无锁化机制加锁，第一种方式：在修改时查询是否与之前查询到的stock一致，但是这样的查询效率过低，我们可以宽松化条件，只要stock大于0即可。

优惠券秒杀一人一单：  
在某些业务场景下，一个用户只能下一个单，而不是让一个用户下多个单子。  
具体实现逻辑：先判断库存，在根据优惠券id和用户id查询是否已经下过这个订单，如果下过这个订单，则不再下单，否则进行下单。  
这里显然也有同步问题，这里我们可以将方法封装，在方法上添加synchronized锁。但是这样添加锁，锁的粒度太粗了，在使用锁过程中，控制锁粒度是一个非常重要的事情。同时在分布式集群下，会存在锁失效问题，这是因为多台tomcat都有属于子集的jvm，因此锁是不同的。因此我们需要引入分布式锁的概念  

## 实践7 分布式锁

分布式锁：满足分布式系统或集群模式下多进程可见并且互斥的锁  
分布式锁的核心思想就是让大家都是用同一把锁，只要大家使用的是同一把锁，那么我们就能锁住线程，不让线程进行，让程序串行执行，这就是分布式锁的核心思路。  
分布式锁应该满足怎么样的条件呢？
- 可见性：多个线程都应该看到相同的结果，注意：这里的可见性并不是并发编程中的内存可见性，而是多个进程之间都能感知到变化的意思。                 -- 互斥： 互斥是分布式锁的最基本的条件，使得程序串行执行
- 高可用：程序不易崩溃，时时刻刻都保证较高的可用性
- 高性能：由于加锁本身就让性能降低，所以分布式锁本身需要他较高的加锁性能高和释放锁性能。
- 安全性：安全也是程序中必不可少的一环

redis作为分布式锁是非常常见的一种使用方式，现在企业级开发中基本都使用redis或者zookeeper作为分布式锁，利用setnx这个方法，如果插入key成功，则表示获得到了锁，如果有人插入成功，其他人插入失败则表示无法获得到锁，利用这套逻辑来实现分布式锁.  

redis分布式锁的实现核心思路

获取锁：  
互斥：确保只能有一个线程获取锁  
非阻塞：尝试一次，成功返回true，失败返回false  

释放锁：  
手动释放  
超时释放：获取锁时添加一个超时时间  

核心思路：我们利用redis的setnx这个方法，当有多个线程进入时，我们就利用该方法，第一个线程进入时，redis中就有这个key了，返回了1，如果结果是1，则表示他抢到了锁，那么他去执行业务，在删除锁，退出锁逻辑，没有抢到锁的等待一定时间后重试即可。  


redis分布式锁误删问题：  

持有锁的线程在锁的内部出现了阻塞，导致他的锁自动释放，这时其他线程，线程2尝试来获取锁，拿到了这把锁，然后线程2在持有锁执行过程中，线程1姬姓执行，删除锁，使得把线程2的锁删除了，这就是误删别人锁的情况说明  
解决方案：在每个线程释放锁的时候，去判断以下当前这把锁是否属于自己，如果属于自己，则不进行锁的删除，假设还是上边的情况，线程1卡顿，锁自动释放，线程2进入到锁的内部执行逻辑，此时线程1继续执行，然后删除所，但是线程1以看当前锁不属于自己，于是不进行删除锁逻辑。  

修改之前的分布式锁实现，在获取锁是存入线程标识(可以用UUID实现)，在释放锁时先获取锁中的线程标识，判断是否与当前线程标识一致。  

分布式锁的原子性问题：  
更为极端的误删情况说明:线程1现在持有锁后，准备删除锁时已经做完锁的标识判断后锁到期了，此时线程2进来上锁，线程1会把线程2的锁删除，这是因为锁的标识判断和锁的删除不是原子性的。  

解决多条命令原子性问题  
 Redis提供了lua脚本，在一个脚本中编写多条Redis命令，可以确保多条命令执行时的原子性。  

但实际上我们前文还留下一个问题没有解决，因为要防止死锁问题的出现，我们给锁都设定了释放时间，但实际上我们很难把控一个业务的具体执行时间，若干执行过程中发生阻塞，那么就可能导致锁的提前释放，这将产生严重的后果。因此我们引入了Redission，其中的watchDog(看门狗)机制能够很好的解决这个问题。  

## 实践八 :分布式锁Redission

基于setnx实现的分布式锁存在以下几个问题：  
1. 重入问题： 重入问题是指获取锁的线程可以再次进入到相同锁的代码块中，可重入锁的意义在于防止死锁，比如HashTable这样的代码中，他的方法都是使用synchronized修饰的,假如在一个方法内，调用该另一个方法则会导致死锁，因此可重入锁的意义是防止死锁，我们的synchronized和Lock锁都是可重入的。
2. 不可重试：是指目前的分布式只能尝试一次，我们认为合理的情况是：当线程在获取锁失败后，他应该能再次尝试获取锁
3. 超时释放：我们在加锁时增加了过期实践，这样我们可以防止死锁
4. 主从一致性：如果Redis提供了主从集群，当我们向集群写入数据时，主机需要异步的将数据同步给从机，而同步时如果主机宕机了，就会出现死锁问题。

Redission是一个在Redis基础上实现的Java驻内存数据网络，它不仅提供了一系列的分布式Java常用对象，还提供了许多分布式服务，其中就包含了各种分布式锁的实现。  

Redission可重入锁原理  
在Lock锁中，他是借助于底层的一个voaltile的一个state变量来记录重入的状态，比如当前没有人持有这把锁，那么state=0，假如有人持有这把锁，那么state=1，如果持有这把锁的人再次持有这把锁，那么state就会+1，如果是对于synchronized而言，也是记录了一个count  
在redission中我们也支持可重入锁,在redission中，在redis的锁设置为hash类型，其中包含了线程标识和value即持有次数，实现了可重入锁的效果。  

锁重试和WatchDog机制  
看门狗机制：解决了业务阻塞但是锁因为超时被释放的问题，如果锁没有被主动释放，并且线程没有宕机，看门狗机制会不断刷新锁的释放时间以避免锁被提前释放。  

MutiLock原理  
为了提高redis的可用性, 我们会搭建集群或主从，现在以主从为例  
此时我们去写命令，写在主机上，主机会将数据同步给从机，但是假设在主机还没有来得及把数据写到从机上去的时候，此时主机宕机，哨兵会发现主机宕机，并且还没有来得及选取slave变成master，而此时新的master中实际上并没有锁的信息，此时锁的信息就丢失了。  
    
解决方法：redission剔除了MutiLock锁，使用这把锁就不是用主从了，每个节点的地位都是一样的，这把锁加锁逻辑需要写入到每个主从节点上，只有所有服务器都写入成功，此时才是加锁成功，假设现在某个节点挂了，那么他去获得锁的时候，只要有一个节点拿不到，都不算是加锁成功，确保了加锁的可靠性。  
当我们去设置多个锁时，redission会将多个锁添加到一个集合中，然后用while循环不停去尝试拿锁，但是会有一个总共的加锁时间，这个时间是用需要加锁的个数 * 1500ms,只有当全部加锁成功才算加锁成功。

## 实践九 秒杀优化-异步优化

当用户发起请求时，此时会请求nginx，nginx会访问到tomcat，而tomcat中程序，会进行串行操作，分为以下几个步骤：  
1. 查询优惠券
2. 判断秒杀库存是否足够
3. 查询订单
4. 校验是否一人一单
5. 扣减库存
6. 创建订单  
在这六步操作中，又有很多操作是要去操作数据库的，而且还是一个线程串行执行，这样就会导致我们的程序执行的很慢，所以我们需要异步程序执行。  
优化方案：我们将耗时比较短的逻辑判断放入到redis中，比如是否库存足够，是否一人一旦，这样的操作，只要这种逻辑可以完成，就意味着我们是一定可以下单完成的，我们只需要进行快速的逻辑判断，不需要下单逻辑走完，直接给用户返回成功，然后在后台开一个线程，后台线程慢慢的去执行queue里的消息。  
涉及到几个问题：  
- 如何快速校验一人一单，还有库存判断
- 由于两个线程，如何在两个线程之间传递成功的消息  
整体思路： 当用户下单后，判断库存是否充足只需要导redis中去根据key找对应的value是否大于0即可，如果不充足，则直接结束，如果充足，继续在redis中判断用户是否可以下单，如果set集合中没有这条数据，说明他可以下单，如果set集合中没有这条记录，则将userId和优惠券存入redis中，并且返回0，整个过程需要保证是原子性的，要用lua脚本操作。  

## Redis消息队列  
什么是消息队列：字面意思就是存放消息的队列。最简单的消息队列模型包括3个
- 消息队列：存储和管理消息，也称为消息代理
- 生产者：发送消息到消息队列
- 消费者：从消息队列中获取消息并处理消息
使用队列的好处在于**解耦:** 所谓解耦，举一个生活的例子就是：快递员(生产者)把快递放到快递柜里边(MQ)去，我们(消费者)从快递柜里边去拿东西，这就是一个异步，如果耦合，那么这个快递员相当于直接把快递交给你。  
秒杀中，我们下单后，利用redis去进行校验下单条件，再通过队列把消息发送出去，然后再启动一个线程去消费这个消息，完成解耦，同时也加快我们的响应速度。  
三种Redis消息队列的实现方式：  
**基于List结构模拟消息队列**  
消息队列就是存放消息的队列，而redis的list数据结构是一个双向链表，很容易模拟出队列效果。  
队列是入口和出口不在一边，因此我们可以利用：LPUSH结合RPOP，或者RPUSH结合LPOP来实现。  
但是队列中没有消息时不会阻塞，这里需要用BRPOP和BLPOP来实现。  
基于List的消息队列有哪些缺点？  
- 优点：
  - 利用Redis存储，不受JVM内存上限
  - 基于Redis的持久化机制，数据安全性有保证
  - 可以满足消息有序性
- 缺点：
  - 无法避免消息丢失
  - 只支持单消费  
**基于PubSub的消息队列**
**PubSub**是Redis2.0版本引入的消息传递模型。顾名思义，消费者可以订阅一个或多个channel，生产者向对应channel发送消息后，所有订阅者都能收到相关信息。  
基于PubSub的消息队列有哪些优缺点？  
- 优点：
  - 采用发布订阅模型，支持多生产、多消费
- 缺点：
  - 不支持数据持久化
  - 无法避免消息丢失
  - 消息堆积有上限，超出时数据丢失

**基于stream的消息队列**  
Stream是Redis5.0引入的一种新的数据类型，可以实现一个功能非常完善的消息队列。

Stream类型消息队列的XREAD命令特点：
- 消息可回溯
- 一个消息可以被多个消费者读取
- 可以阻塞读取
- 有消息漏读的风险

**基于stream的消息队列-消费者组**  
消费者组：将多个消费者划分到一个组中，监听同一个队列，具备下列特点：
- 消息分流，队列中的消息会分流给组内的不同消费者，而不是重复消费，从而加快了消息处理的速度
- 消费者会维护一个标识，记录最后一个被处理的消息，哪怕消费者宕机重启，还会从标识之后读取消息，确保每一个消息都会被消费。
- 消息确认，消费者获取消息后，消息处于pending状态，并存入一个pending-list，当处理完成后需要通过XACK来确认消息，标记消息为已处理，才会从pending-list移除。  
消费者组的特点：
- 消息可回溯
- 可以多消费者争抢消息，加快消费速度
- 可以阻塞读取
- 没有消息漏读风险
- 有消息确认机制，保证消息至少被消费一次

## 实践十 达人探店

点赞功能实现：  
需求分析：  
- 同一个用户只能点赞一次，再次点击则取消点赞
- 如果当前用户已经点赞，则点赞按钮高亮显示  
这里采用set集合，记录用户点赞的blogid，这样就无法重复了  

点赞排行榜功能实现：  
在笔记详情页面，要把先点赞的人显示出来，形成点赞排行榜。之前点赞是放到set集合中，但是set集合是不能排序的，所以这个时候，可以采用一个可以排序的set集合，就是sortedSet。  

关注相关功能一致，这里不再赘述

 好友关注-Feed流实现方案  
 当我们关注了用户后，这个用户发了动态，那么我们应该把这些数据推送给用户，这个需求我们叫做Feed流。Feed流产品有两种常见模式：TimeLine：不做内容筛选，简单的按照内容发布实践排序，常用于好友或关注。  
 Timeline的模式，有三种实现方式：  
 - 拉模式
 - 推模式
 - 推拉结合  

 **拉模式**：也叫做读扩散
 该模式的核心含义就是：当张三和李四和王五发了消息后，都会保存在自己的邮箱中，假设赵六要读取信息，那么他会从读取他自己的收件箱，此时系统会从他关注的人群中，把他关注人的信息全部都进行拉取，然后在进行排序。  
 优点：比较节约实践，因为赵六在读信息时，并没有重复读取，而且读取完之后可以把他的收件箱进行清除。  
 缺点： 有延迟，用户读取数据时才去关注的人里边去读取数据，假设用户关注了大量用户，那么此时会拉去海量的内容，对服务器压力巨大。  
 **推模式**：也叫做写扩散
推模式是没有写邮箱的，当张三写了一个内容，此时会主动的把张三写的内容发送给他的粉丝收件箱去，假设此时李四再来读取，就不用去临时拉取了  
优点：时效快，不用临时拉取  
缺点：内存压力大，假设一个大V写信息，很多人关注他，就会写成很多份数据到粉。  
**推拉结合**,就是把这两种模式结合起来.  

Feed流的滚动分页  
我们需要记录每次操作的最后一条，然后从这个位置开始去读取数据。  
举个例子：我们从t1时刻开始，拿第一页数据，拿到了10-6，然后记录下当前最后一次拿取的记录，也就是6，t2时刻发布了新的记录，此时这个11放到最顶上，但是不会影响我们之前记录的6，此时t3时刻来拿第二页，第二页这个时候拿数据，还是从6后面的5开始取。这里采用sortedset来实现范围查询，记录当前获取时间错的最小值，然后实现滚动分页。(考虑如B站类似的视频推送可以通过createTime实现时间戳效果)  

## 实践十一 用geo实现附近商户问题

## 实践十二 使用bitmap实现用户签到功能  
ps：bitmap还可以实现布隆过滤器，利用哈希映射将数据库的id映射到bitmap位上，但是考虑到哈希冲突，所以存在一定的误差率。

## 实践十三 UV统计

## 高级篇

### 分布式缓存
基于redis集群来解决单机redis存在的问题：  

单机的redis存在四大问题：
- 数据丢失问题，实现redis数据持久化
- 并发能力问题，搭建主从集群，实现读写分离
- 搭建分片集群，利用插槽机制实现动态扩容
- 故障恢复问题，利用Redis哨兵，实现监控检测和自动恢复  

**Redis持久化**
- RDB持久化
- AOF持久化

RDB持久化  
RDB全称Redis Database Backup file，也被叫做Redis数据快照。简单来说就是把内存中的所有数据都记录到磁盘中。当Redis实例故障重启后，从磁盘读取快照文件，恢复数据。快照文件称为RDB文件，默认是保存在当前运行目录

执行时机
- 执行save命令(阻塞保存)
- 执行bgsave命令(异步保存)
- Redis停机时
- 触发RDB条件时

RDB原理
bgsave开始时会fork主进程得到子进程，子进程共享主进程的内存数据。完成fork后读取内存数据并写入RDB文件  
fork采用的是cow技术：
- 当主机进程执行读操作时，会访问共享内存
- 当主进程执行写操作时，则会拷贝一份数据，执行写操作  

其实就是懒惰的一种策略，因为都是读的话，没有对数据进行更改操作，因此不需要分配新的内存空间，但一旦发生了写操作，就会导致数据上的不一致，因此要重新分配操作。  

RDB方式bgsave的基本流程？
- fork主进程得到一个子进程，共享内存空间
- 子进程读取内存数据并写入新的RDB文件
- 用新的RDB文件替换旧的RDB文件

AOF原理  
AOF全称位Append Only File(追加文件)。Redis处理的每一个写命令都会记录在AOF文件，可以看做是命令日志文件。  

AOF文件重写  
因为是记录命令，AOF文件会比RDB文件大得多。而且AOF会记录对同一个key的多次写操作，但只有最后一次写操作才有意义。通过执行bgrewriteaof命令，可以让aof文件执行重写功能，用最少的命令达到相同效果。  

AOF与RDB
- 数据完整性：RDB不完整，两份备份之间会丢失，AOF相对完整，取决于刷盘策略
- 数据恢复优先级：RDB数据完整性不如AOF

## Redis主从
单节点Redis的并发能力是有上限的，要进一步提高Redis的并发能力，就需要搭建主从集群，实现读写分离。

**全量同步**
主从第一次建立连接时，会执行全量同步，将master节点的所有数据都拷贝给slave节点，流程：  
1. slave节点请求增量同步
2. master节点判断replid，发现不一致，拒绝增量同步
3. master将完整内存数据生成RDB，发送RDB给slave
4. slave清空本地数据，加载master的RDB
5. master将RDB期间的命令记录在repl_baklog, 并持续将log中的命令发送给slave
6. slave执行接受到的命令，保持与master之间同步  
这里有两个变量：replyid和offset，replyid判断是否是一个master数据，offset判断读到的偏移量  

**增量同步**
全量同步需要先做RDB，然后将RDB文件通过网络传输给slave，成本太高了。因此除了第一次做全量同步，其他大多时候slava与master都是做增量同步。即只更新slave与master存在差异的部分数据。  

**repl_backlog原理**
master怎么知道slave与自己的数据差异在哪里呢？repl_backlog文件是一个固定大小的数组，只不过数组是环形，也就是说角标到达数组末尾，会再次从0开始读写，这样数组头部的数据就会被覆盖。repl_backlog会记录Redis处理过命令日记及offset，比较offset就是需要增量的数据，但是需要注意的是如果slave出现了网络阻塞，导致这个环形数组被重写一圈后覆盖了，这样必须再执行一次全量同步。

**主从同步优化**
主从同步可以保证主从数据的一致性，非常重要：  
从以下几个方面来优化Redis的主从集群：
- 在master配置repl_diskless_sync yes 启用无磁盘复制，避免全量同步时的磁盘IO
- 磁盘单节点上的内存占用不要太大，减少RDB导致的过量磁盘IO
- 适当提高repl_baklog的大小，发现slave宕机时尽快实现故障恢复，尽可能避免全量同步
- 限制一个master上的slave节点数量，如果实在是太多slave，则可以采用主-从-从链式结构，减轻master压力

## Redis哨兵
Redis提供了哨兵机制来实现主从集群的自动故障恢复  

哨兵作用如下：
- 监控：Sentinel会不断检查master和slave是否按照预期工作
- 自动故障恢复：如果master故障，Sentinel会将slave提升为master
- 通知：Sentinel充当Redis客户端的服务发现来源，当集群发生故障转移时，会将最新消息推送到Redis客户端  

**集群监控原理**
Sentinel基于心跳机制检测服务状态，每隔1秒向集群的每个实例发送ping命令：
- 主观下线：如果某sentinel节点发现某实例未在规定时间响应，则认为该实例主管下线。
- 客观下线：若超过指定数量的sentinel都认为该实例主观下线，则该实例客观下线。  

**集群故障恢复原理**
一旦发现master故障，sentinel需要在salve中选择一个作为新的master，选择依据是这样的：
- 首先会判断slave节点与master节点断开时间长短，如果超过指定值则会排除该slave节点
- 然后判断slave节点的slave-priority值，越小优先级越高，如果是0则永不参与选举
- 如果slave-priority一样，则判断slave节点的offset值，如果越大说明数据越新
- 最后判断slave节点的运行id大小，越小优先级越高。

流程如下：  
1. sentinel给备选的slave节点发送slave of no one命令，让该节点成为master
2. sentinel给所有其他slave发送命令，让slave成为新master的从节点，同时开始同步数据
3. 最后将故障节点标记为slave，故障节点恢复后自动成为新master的slave节点

## Redis分片集群  
主从和哨兵可以解决高可用、高并发读的问题。但是依然还有两个问题没有解决：
- 海量数据存储问题
- 高并发写问题

使用分片集群可以解决上述问题  
分片集群特征：
- 集群中有多个master，每个master保存不同数据
- 每个master都可以有多个slave节点
- master之间通过ping检测彼此健康状态
- 客户端请求可以访问集群任意节点，最终都会被转发到正确节点  

插槽原理  
Redis会把每一个master节点映射到0~16383共16384个插槽上，查看集群信息时可以看到：数据key不是与节点绑定，而是与插槽绑定。redis会根据key的有效部分计算插槽值，分为两种情况：
- key中包含“{}”，且“{}”中至少包含一个字符，“{}”中的部分是有效部分
- key中不包含“{}”，整个key都是有效部分

## 多级缓存

在我们之前的项目中存在以下几个问题：
- 请求要经过Tomcat处理，Tomcat的性能成为整个系统的瓶颈
- Redis缓存失效时，会对数据库产生冲击  

多级缓存就是充分利用请求处理的每个环节，分别添加缓存，减轻Tomcat压力，提升服务性能：
- 浏览器访问静态资源时，优先读取浏览器本地缓存
- 访问非静态资源(ajax查询数据)时，访问服务端
- 请求到达nginx时，优先读取Nginx本地缓存
- 如果nginx本地缓存未命中，直接去查询Redis(不经过Tomcat)
- 如果Redis查询未命中，则查询Tomcat
- 请求进入Tomcat后，优先查询JVM进程缓存
- 如果JVM进程缓存未命中，则查询数据库

在多级缓存架构中，Nginx内部需要编写本地缓存查询、Redis查询、Tomcat查询的业务逻辑，因此这样的nginx服务不再是一个反向代理服务器，而是一个编写业务的web服务器了。

多级缓存的关键有两个：
- 在nginx中编写业务，实现nginx本地缓存、Redis、Tomcat的查询
- 另一个就是在Tomcat中实现JVM进程缓存

**JVM进程缓存**  

缓存在日常开发中启动至关重要的作用，由于是存储在内存中，数据的读取速度是非常快的，能大量减少对数据库的访问，减少数据库的压力，我们把缓存分为两类：
- 分布式缓存，例如Redis：
  - 优点：存储容量更大、可靠性更好、可以在集群间共享
  - 缺点: 访问缓存有网络开销
  - 场景：缓存数据量比较大、可靠性要求比较高、需要在集群键共享
- 进程本地缓存，例如HashMap、GuavaCache：
  - 优点：读取本地内存，没有网络开销，速度更快
  - 缺点：存储容量有限，可靠性较低，无法共享
  - 场景：性能要求较高，缓存数据量较小

这里使用Caffeine框架实现JVM进程缓存  
Caffeine提供了三种缓存驱逐策略：
- 基于容量：设置缓存的数量上限
- 基于时间：设置缓存的有效时间
- 基于引用：设置缓存为软引用或弱引用，利用GC来回收缓存数据。性能较差不建议使用

这里不谈论nginx的缓存  

**Redis缓存预热**
Redis缓存会面临冷启动问题：
- 冷启动：服务刚刚启动时，Redis中并没有缓存，如果有所商品数据都在第一次查询时添加缓存，可能会给数据库带来较大压力。
- 缓存预热：在实际开发中，我们可以利用大数据统计用户访问的热点数据，在项目启动时将这些热点数据提前查询并保存到Redis中。

**数据同步策略**
缓存数据同步的常见方式有三种：
- 设置有效期：给缓存设置有效期，到期后自动删除。再次查询时更新
  - 优势：简单、方便
  - 缺点：时效性差，缓存过期之前可能不一致
  - 场景：更新频率较低，时效性要求低的业务
- 同步双写：在修改数据库的同时，直接修改缓存
  - 优势：时效性强，缓存与数据库强一致
  - 缺点：有代码侵入，耦合度高
  - 场景：对一致性、时效性要求较高的缓存数据
- 异步通知：修改数据库时发送事件通知，相关服务监听到通知后修改缓存服务
  - 优势：低耦合，可以同时通知多个缓存服务
  - 缺点: 时效性一般，可能存在中间不一致状态
  - 场景：时效性要求一般，有多个服务需要同步

其中异步通知有MQ和Canal两种解决方案，这里介绍Canal

Canal是基于MySql的主从同步来实现的，MySQL主从同步的原理如下：
- Mysql master将数据变更写入二进制日志(binary log), 其中记录的数据叫做binary log events
- MysqL slave将master的binary log events拷贝到它的中继日记
- Mysql slave重放relay log中事件，将数据变更反映到自己的数据中。
